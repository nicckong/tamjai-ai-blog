# TamJai AI Jeh Jeh: A Real-World LLM Project for Hong Kong's Food Scene

## Introduction

TamJai Yunnan Mixian, or just TamJai, as locals call it, is a Hong Kong staple. Itâ€™s cheap, customizable, and everywhere. I eat it often, but I always wondered: do people really feel differently about different branches? Are some actually better?

This got me thinking:  
**â€œIf Iâ€™m in a new area, how do I know which TamJai to try, or skip?â€**

That curiosity led to this side project: **TamJai AI Jeh Jeh**, an assistant that digs into public customer review data to answer everyday questions like:
- Which branches are most highly rated?
- How do people feel about TamJai in my district?
- What dishes come up the most?

It was a chance to explore new AI tools, tackle messy multilingual data, and design something genuinely useful. The result? An AI assistant that summarizes reviews, compares locations, spots trends, and switches between English and Traditional Chinese, all powered by real, unedited customer feedback.

---

## How It Works

### Data:
All review data was collected from OpenRice, Hong Kongâ€™s largest restaurant review platform. This included:
	- Branch-level metadata (e.g. name, location, timestamps)
	- User-submitted ratings (food, service, environment, hygiene, value)
	- Multilingual text reviews (in English and Traditional Chinese)

The raw data was preserved as-is, without manual modifications.

Review texts were embedded using Vertex AI Embeddings and stored in ChromaDB for semantic search.
*Chroma was chosen for its lightweight footprint, metadata filtering support, and free self-hosting, ideal for prototyping side projects*

Review and branch metadata were stored in a PostgreSQL database to support quantitative queries.
*PostgreSQL was selected for its reliability, schema flexibility, and strong compatibility with analytics workflows.*

### Frontend:
A web app built with Streamlit UI, where users type questions, toggle languages (English / Traditional Chinese), switch themes, and keep chat history in session memory.

### Backend:
1. When the user submits a question, the MCP Client first fetches the latest tool catalog from the MCP Server.
2. It then sends both the catalog and the userâ€™s question to the LLM running inside the client.
3. The LLM intelligently selects the most relevant tool based on the queryâ€™s intent.
4. That chosen tool is invoked, and the processed result is sent back to the MCP Client, which then returns the final answer via the Streamlit app.

### Tools Registered in MCP Server
1. **Summarization**  
   - Powered by LangGraph + ChromaDB for semantic vector search and bilingual summarization

2. **Math Tool**  
   - Translates natural language queries into SQL
   - Queries a PostgreSQL database of review metadata

3. **Comparison**  
   - Designed for comparing branches, districts, or areas
   - Merges numeric insights (from the Math Tool) with qualitative results (from Summarization)

4. **Charting**  
   - Renders interactive Plotly charts directly in the Streamlit interface

### Extras:
- Modular backend design enables easy expansion of tools
- Google Cloud Storage handles vector synchronization and asset hosting
- Prompts are finely tuned for accurate bilingual output

### Why MCP?

The Model Context Protocol (MCP) is an open-standard client-server framework, often called the â€œUSBâ€‘C for AIâ€. It standardizes how LLMs connect to tools, data sources, and contextual workflow. 

---

## Key Features & Demo

TamJai AI Jeh Jeh is built to be friendly, flexible, and usefulâ€”especially in a real Hong Kong setting. Here's what it can do:

### 1. Natural Language Q&A
Ask questions in English or Traditional Chinese. The assistant semantically searches reviews and summarizes them clearly, even across branches, districts and menu items.  
Example:  
"å¹«æˆ‘ç¸½çµèƒç£å€åˆ†åº—åœŸåŒªé›ç¿¼çš„è©•åƒ¹"

<video width="640" controls>
  <source src="../assets/mp4/demo_q1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

### 2. Branch Comparison (Quant + Qual)
Compare any locations side-by-side. See review counts, average ratings, and actual customer feedback. A mix of numbers and review summaries.  
Example:  
"æ¯”è¼ƒè§€å¡˜å€åŒå°‡è»æ¾³å€åˆ†åº—å˜…è©•åƒ¹"

<video width="640" controls>
  <source src="../assets/mp4/demo_q1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

### 3. Interactive Charts
Trend charts and rankings powered by Plotly, all inside the app. Explore top branches, review counts, and district-level insights visually.  
Example:  
"Plot the number of reviews by branch in Tsuen Kwan O"

<video width="640" controls>
  <source src="../assets/mp4/demo_q1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

### 4. Multi-part Questions
The AI can break the question into multiple parts and return a single answer.  
Example:  
"Which branch has most reviews in 2025? Summarize the reviews for this branch."

<video width="640" controls>
  <source src="../assets/mp4/demo_q1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

---

## What I Learned

This project was more than just a technical experiment. It was hands-on practice in building AI systems that address real-world problems and are genuinely enjoyable to use.

Key takeaways:
- **Prompt design is crucial.** Small tweaks to phrasing significantly improved both the quality and tone of the LLMâ€™s responses.
- **Modular design pays off.** By registering each tool separately in MCP, I was able to add or swap functionality independently without affecting the rest of the system, demonstrating true modularity in practice.
- **Messy data is the norm.** Reviews are full of slang and inconsistencies, so I needed robust fallback logic.
- **AI = product thinking.** Itâ€™s not just about models. Itâ€™s about full-stack experience design.
- **Cloud deployment & DevOps mindset** Deploying the backend (VM, ChromaDB, Postgres, etc.) on Google Cloud Platform taught me essential skills around infrastructure setup, secure resource access, and cost optimization, keys for reliable real-world AI services

---

## Next Steps

While this is an MVP, here are ideas Iâ€™d love to explore further:

- **ğŸ“ˆ More Chart Options**
  - Let users pick chart types (bar, pie, line)
  - Add downloadable insights or reports

- **ğŸ’¬ Contextual Conversations**
  - Add short-term chat memory for natural follow-ups
  - Gracefully prompt for clarification on vague queries

- **ğŸ§  Better Summaries and Patterns**
  - Improve sentiment interpretation
  - Cluster feedback for recurring themes

- **ğŸŒ Expandability**
  - Apply the framework to other restaurant chains or domains
  - Package as a feedback analytics template

---

## Final Thoughts

This project started with a food craving â€” and ended up being a complete lesson in building AI tools that serve real people in a real city.

From data wrangling and prompt tuning to cloud costs and product polish, the TamJai Assistant helped me grow across technical and product dimensions. Itâ€™s proof that good AI doesnâ€™t have to be flashy â€” just helpful, honest, and human-centered.

Thanks for reading!  
If you're working at the intersection of product, data, and AI, [letâ€™s connect on LinkedIn](https://www.linkedin.com/in/nicckong/).

---

## Disclaimer

This project is not affiliated, endorsed by, or conducted in collaboration with TamJai Yunnan Mixian or any of its associated entities ("TamJai"). All data used comes from public sources and has not been modified. All analyses, visualizations, and conclusions are generated based on publicly available information and AI-assisted processing. They are for reference only and do not represent the views of the author or TamJai.