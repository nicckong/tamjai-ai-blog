<style>
/* Base styles (light mode) */
body {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
  line-height: 1.6;
  font-size: 16px;
  color: #222;
  background-color: #fff;
  padding: 0 16px;
  max-width: 800px;
  margin: 0 auto;
}
h1 {
  font-family: 'Inter', sans-serif !important;
  color: #111;
  padding-bottom: 0.2em;
  font-size: 32px !important;
  font-style: normal; 
  font-weight: 700;
  letter-spacing: -0.014em;
  line-height: 38px;
  margin-top: 1.01em;
  margin-bottom: -0.27em;
  border-bottom: none !important;
}
h2 {
  color: #111;
  margin-top: 2em !important;
  padding-bottom: 0.2em;
  font-size: 20px !important;
  border-bottom: none !important;
}
h3 {
  color: #111;
  margin-top: 2em;
  padding-bottom: 0.2em;
  font-size: 16px !important;
  border-bottom: none !important;
}

/* Dark mode overrides */
@media (prefers-color-scheme: dark) {
  body { background-color: #121212; color: #eee; }
  h1, h2, h3 { color: #f2f2f2; }
}
</style>

# TamJai AI Jeh Jeh: A Real-World LLM Project for Hong Kong's Food Scene

<p align="center">
  <img src="https://nicckong.github.io/tamjai-ai-blog/assets/jpg/image.jpeg" alt="Cover Image" width=60% />
</p>

<p align="center">
  <img src="/tamjai-ai-blog/assets/jpg/image.jpeg" alt="Cover Image" width=60% />
</p>

## Introduction

TamJai Yunnan Mixian, or just TamJai, as locals call it, is a Hong Kong staple. It’s cheap, customizable, and everywhere. I eat it often, but I always wondered: do people really feel differently about different branches? Are some actually better?

This got me thinking:  
**“If I’m in a new area, how do I know which TamJai to try, or skip?”**

That curiosity led to this side project: **TamJai AI Jeh Jeh**, an assistant that digs into public customer review data to answer everyday questions like:
- Which branches are most highly rated?
- How do people feel about TamJai in my district?
- What dishes come up the most?

It was a chance to explore new AI tools, tackle messy multilingual data, and design something genuinely useful. The result? An AI assistant that summarizes reviews, compares locations, spots trends, and switches between English and Traditional Chinese, all powered by real, unedited customer feedback.

## How It Works

### Data:
All review data was collected from OpenRice, Hong Kong’s largest restaurant review platform. This included:
	- Branch-level metadata (e.g. name, location, timestamps)
	- User-submitted ratings (food, service, environment, hygiene, value)
	- Multilingual text reviews (in English and Traditional Chinese)

The raw data was preserved as-is, without manual modifications.

Review texts were embedded using Vertex AI Embeddings and stored in ChromaDB for semantic search. Chroma was chosen for its lightweight footprint, metadata filtering support, and free self-hosting, ideal for prototyping side projects

Review and branch metadata were stored in a PostgreSQL database to support quantitative queries. PostgreSQL was selected for its reliability, schema flexibility, and strong compatibility with analytics workflows.

### Frontend:
A web app built with Streamlit UI, where users type questions, toggle languages (English / Traditional Chinese), switch themes, and keep chat history in session memory.

### Backend:
1. When the user submits a question, the MCP Client first fetches the latest tool catalog from the MCP Server.
2. It then sends both the catalog and the user’s question to the LLM running inside the client.
3. The LLM intelligently selects the most relevant tool based on the query’s intent.
4. That chosen tool is invoked, and the processed result is sent back to the MCP Client, which then returns the final answer via the Streamlit app.

### Tools Registered in MCP Server
1. **Summarization**  
   - Powered by LangGraph + ChromaDB for semantic vector search and bilingual summarization

2. **Math Tool**  
   - Translates natural language queries into SQL
   - Queries a PostgreSQL database of review metadata

3. **Comparison**  
   - Designed for comparing branches, districts, or areas
   - Merges numeric insights (from the Math Tool) with qualitative results (from Summarization)

4. **Charting**  
   - Renders interactive Plotly charts directly in the Streamlit interface

### Extras:  
- Modular backend design enables easy expansion of tools
- Google Cloud Storage handles vector synchronization and asset hosting
- Prompts are finely tuned for accurate bilingual output

### Why MCP?

The Model Context Protocol (MCP) is an open-standard client-server framework, often called the “USB‑C for AI”. It standardizes how LLMs connect to tools, data sources, and contextual workflow. 

## Key Features & Demo

TamJai AI Jeh Jeh is built to be friendly, flexible, and useful—especially in a real Hong Kong setting. Here's what it can do:

### 1. Natural Language Q&A
Ask questions in English or Traditional Chinese. The assistant semantically searches reviews and summarizes them clearly, even across branches, districts and menu items.  
Example:  
"幫我總結荃灣區分店土匪雞翼的評價"

![Demo 1](https://nicckong.github.io/tamjai-ai-blog/assets/gifs/demo_q1.gif)

### 2. Branch Comparison (Quant + Qual)
Compare any locations side-by-side. See review counts, average ratings, and actual customer feedback. A mix of numbers and review summaries.  
Example:  
"比較觀塘區同將軍澳區分店嘅評價"

![Demo 2](https://nicckong.github.io/tamjai-ai-blog/assets/gifs/demo_q2.gif)

### 3. Interactive Charts
Trend charts and rankings powered by Plotly, all inside the app. Explore top branches, review counts, and district-level insights visually.  
Example:  
"Plot the number of reviews by branch in Tsuen Kwan O"

![Demo 3](https://nicckong.github.io/tamjai-ai-blog/assets/gifs/demo_q3.gif)

### 4. Multi-part Questions
The AI can break the question into multiple parts and return a single answer.  
Example:  
"Which branch has most reviews in 2025? Summarize the reviews for this branch."

![Demo 4](https://nicckong.github.io/tamjai-ai-blog/assets/gifs/demo_q4.gif)

## What I Learned

This project was more than just a technical experiment. It was hands-on practice in building AI systems that address real-world problems and are genuinely enjoyable to use.

Key takeaways:
- **Prompt design is crucial.** Small tweaks to phrasing significantly improved both the quality and tone of the LLM’s responses.
- **Modular design pays off.** By registering each tool separately in MCP, I was able to add or swap functionality independently without affecting the rest of the system, demonstrating true modularity in practice.
- **Messy data is the norm.** Reviews are full of slang and inconsistencies, so I needed robust fallback logic.
- **AI = product thinking.** It’s not just about models. It’s about full-stack experience design.
- **Cloud deployment & DevOps mindset** Deploying the backend (VM, ChromaDB, Postgres, etc.) on Google Cloud Platform taught me essential skills around infrastructure setup, secure resource access, and cost optimization, keys for reliable real-world AI services

## Next Steps

While this is an MVP, here are a few directions I’d love to explore further:

- **More Charting Options**
  - Let users choose chart types (bar, pie, line)
  - Add options to download insights or reports

- **Contextual Conversations**
  - Introduce short-term chat memory for more natural follow-ups
  - Prompt users gracefully when queries are ambiguous

- **Smarter Summaries & Insights**
  - Refine sentiment interpretation
  - Build on existing clustering to better surface recurring themes and anomalies
  
- **Broader Use Cases**
  - Extend the framework to other restaurant chains or domains
  - Package the pipeline as a reusable feedback analytics template

## Final Thoughts

This project started with a food craving — and ended up being a complete lesson in building AI tools that serve real people in a real city.

From data wrangling and prompt tuning to cloud costs and product polish, the TamJai Assistant helped me grow across technical and product dimensions. It’s proof that good AI doesn’t have to be flashy — just helpful, honest, and human-centered.

Thanks for reading!  
If you're working at the intersection of product, data, and AI, let’s connect on [LinkedIn](https://www.linkedin.com/in/nicckong/).

## Disclaimer

This project is not affiliated, endorsed by, or conducted in collaboration with TamJai Yunnan Mixian or any of its associated entities ("TamJai"). All data used comes from public sources and has not been modified. All analyses, visualizations, and conclusions are generated based on publicly available information and AI-assisted processing. They are for reference only and do not represent the views of the author or TamJai.